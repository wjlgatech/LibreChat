<!DOCTYPE html>
<html>
<head>
    <title>Basic Speech Recognition Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
        }
        button {
            padding: 10px 20px;
            font-size: 16px;
            margin: 10px;
            cursor: pointer;
        }
        #status {
            margin: 20px 0;
            padding: 10px;
            background: #f0f0f0;
            border-radius: 5px;
        }
        #transcript {
            margin: 20px 0;
            padding: 10px;
            background: #e0e0e0;
            border-radius: 5px;
            min-height: 100px;
        }
        .active { background: #4CAF50; color: white; }
        .error { background: #f44336; color: white; }
    </style>
</head>
<body>
    <h1>Basic Speech Recognition Test</h1>
    
    <button id="startBtn">Start Recognition</button>
    <button id="stopBtn" disabled>Stop Recognition</button>
    
    <div id="status">Status: Ready</div>
    <div id="transcript">Transcript will appear here...</div>
    
    <script>
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const status = document.getElementById('status');
        const transcript = document.getElementById('transcript');
        
        let recognition = null;
        let fullTranscript = '';
        
        function updateStatus(msg, isError = false) {
            status.textContent = `Status: ${msg}`;
            status.className = isError ? 'error' : '';
            console.log(`[Status] ${msg}`);
        }
        
        function initRecognition() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            
            if (!SpeechRecognition) {
                updateStatus('Speech recognition not supported', true);
                return null;
            }
            
            const rec = new SpeechRecognition();
            rec.continuous = true;
            rec.interimResults = true;
            rec.lang = 'en-US';
            
            rec.onstart = () => {
                updateStatus('Listening... Speak now!');
                startBtn.disabled = true;
                stopBtn.disabled = false;
                startBtn.className = '';
                stopBtn.className = 'active';
            };
            
            rec.onresult = (event) => {
                let interimTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const result = event.results[i];
                    if (result.isFinal) {
                        fullTranscript += result[0].transcript + ' ';
                    } else {
                        interimTranscript += result[0].transcript;
                    }
                }
                
                transcript.innerHTML = `
                    <strong>Final:</strong> ${fullTranscript}<br>
                    <strong>Interim:</strong> ${interimTranscript}
                `;
            };
            
            rec.onerror = (event) => {
                updateStatus(`Error: ${event.error}`, true);
                console.error('Recognition error:', event);
                
                if (event.error === 'no-speech') {
                    updateStatus('No speech detected - try speaking louder');
                } else if (event.error === 'not-allowed') {
                    updateStatus('Microphone permission denied', true);
                }
                
                startBtn.disabled = false;
                stopBtn.disabled = true;
                startBtn.className = 'active';
                stopBtn.className = '';
            };
            
            rec.onend = () => {
                updateStatus('Recognition ended');
                startBtn.disabled = false;
                stopBtn.disabled = true;
                startBtn.className = 'active';
                stopBtn.className = '';
            };
            
            // Additional events for debugging
            rec.onspeechstart = () => console.log('Speech detected!');
            rec.onspeechend = () => console.log('Speech ended');
            rec.onaudiostart = () => console.log('Audio capture started');
            rec.onaudioend = () => console.log('Audio capture ended');
            
            return rec;
        }
        
        startBtn.onclick = async () => {
            try {
                // First check microphone permission
                updateStatus('Checking microphone permission...');
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                stream.getTracks().forEach(track => track.stop());
                
                updateStatus('Starting recognition...');
                
                if (!recognition) {
                    recognition = initRecognition();
                }
                
                if (recognition) {
                    fullTranscript = '';
                    transcript.textContent = 'Listening...';
                    recognition.start();
                }
            } catch (error) {
                updateStatus(`Error: ${error.message}`, true);
                console.error('Start error:', error);
            }
        };
        
        stopBtn.onclick = () => {
            if (recognition) {
                recognition.stop();
                updateStatus('Stopping...');
            }
        };
        
        // Initialize
        updateStatus('Ready - Click "Start Recognition" to begin');
        startBtn.className = 'active';
    </script>
</body>
</html>